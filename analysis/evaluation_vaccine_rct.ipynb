{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import krippendorff\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "survey_data = pd.read_csv(\"../data/duch_et_al_2023_vaccine_financial_vaccine_intention_training.csv\", header=1)\n",
    "NUM_SUBJECTS = len(survey_data)\n",
    "EXPERIMENT_ROUND = 'round9'\n",
    "\n",
    "demographic_questions = [\n",
    "    \"Start Date\",\n",
    "    \"What is your current age?\",\n",
    "    \"What is your gender?\",\n",
    "    \"What is the highest educational qualification you have completed?\",\n",
    "    \"Which region do you live in?\",\n",
    "    \"Which distric do you live in?\",\n",
    "    \"What is the name of the community you live in?\",\n",
    "    \"How many people live in your village?\",\n",
    "    \"What is the distance in km of the nearest health clinic from where you live?\",\n",
    "    \"How many people live in the house together with you (NOT including you) at this moment?\",\n",
    "    \"How many children below 18 years old are currently living in your home?\",\n",
    "    \"What is your current working situation?\",\n",
    "    \"How much (in Ghanaian Cedis) on average does your household spend in a typical week on food?\",\n",
    "    \"How much (in Ghanaian Cedis) on average does your household spend in a typical week on non-food items (electricity, water, rent, school fees)?\",\n",
    "    \"How would you rate the overall economic or financial condition of your household today?\",\n",
    "    \"Do you have a registered mobile number?\",\n",
    "    \"How many family members do you have in another village?\",\n",
    "    \"How many friends and acquaintances who are not part of your family do you have in another village?\",\n",
    "    \"How many individuals can you identify in your social network? Think of friends and relatives that live close to you\",\n",
    "    \"How often do you use social media?\",\n",
    "]\n",
    "\n",
    "survey_questions = [\n",
    "    \"Do you think you will get a first shot of a COVID-19 vaccine within the first 6 weeks after the vaccine becomes available to you?\"\n",
    "]\n",
    "\n",
    "survey_data = survey_data[['ID'] + demographic_questions + survey_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cramer's V function\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2_corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    r_corr = r - ((r-1)**2)/(n-1)\n",
    "    k_corr = k - ((k-1)**2)/(n-1)\n",
    "    epsilon = 1e-10  # Small value to prevent division by zero\n",
    "    return np.sqrt(phi2_corr / max(min((k_corr-1), (r_corr-1)), epsilon))\n",
    "\n",
    "\n",
    "# Define the custom mapping function\n",
    "def map_response(response, question):\n",
    "    if question == \"Do you think you will get a first shot of a COVID-19 vaccine within the first 6 weeks after the vaccine becomes available to you?\":\n",
    "        if response == \"Yes\":\n",
    "            return 1\n",
    "        elif response == \"No\":\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        raise ValueError(f\"{question} is not considered!\")\n",
    "\n",
    "\n",
    "def evaluate_responses(prompts_with_responses: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate the LLM's ability to predict the ground truth responses.\n",
    "\n",
    "    Parameters:\n",
    "        prompts_with_responses (pd.DataFrame): A DataFrame containing the prompts and the corresponding responses.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics for each question.\n",
    "    \"\"\"\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for question in prompts_with_responses[\"question\"].unique():\n",
    "        question_responses = prompts_with_responses[\n",
    "            prompts_with_responses[\"question\"] == question\n",
    "        ]\n",
    "\n",
    "        # Categorical evaluation\n",
    "        response_type = \"Categorical\"\n",
    "        evaluation_result = evaluate_categorical_response(\n",
    "            question_responses[\"user_response\"], question_responses[\"llm_response\"], question\n",
    "        )\n",
    "\n",
    "        evaluation_results[question] = {\n",
    "            \"response_type\": response_type,\n",
    "            \"evaluation_result\": evaluation_result,\n",
    "        }\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "\n",
    "def format_response(response: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Formats a pandas Series containing strings by removing all special characters,\n",
    "    leading and trailing whitespaces, and converting all characters to lower case.\n",
    "\n",
    "    Parameters:\n",
    "        response (pd.Series): A pandas Series containing the strings to be formatted.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A pandas Series containing the formatted strings.\n",
    "    \"\"\"\n",
    "    formatted_response = response.str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True).str.strip()\n",
    "    return formatted_response\n",
    "\n",
    "\n",
    "def evaluate_categorical_response(\n",
    "    user_response: pd.Series, llm_response: pd.Series, question: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate the LLM's ability to predict the user's categorical response in terms of\n",
    "    cramer's V correlation, accuracy, F1 score, and Matthews correlation coefficient.\n",
    "\n",
    "    Parameters:\n",
    "        user_response (pd.Series): A pandas Series containing the user's responses.\n",
    "        llm_response (pd.Series): A pandas Series containing the LLM's responses.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Remove all special characters and convert text to lower case\n",
    "    formatted_user_response = format_response(user_response)\n",
    "    formatted_llm_response = format_response(llm_response)\n",
    "\n",
    "    formatted_user_response = formatted_user_response.apply(lambda response: map_response(response, question))\n",
    "    formatted_llm_response = formatted_llm_response.apply(lambda response: map_response(response, question))\n",
    "\n",
    "    # Mask the invalid responses from LLM\n",
    "    invalid_indices = formatted_llm_response[formatted_llm_response == -1].index\n",
    "    print(len(invalid_indices))\n",
    "    user_response_cleaned = formatted_user_response.drop(index=invalid_indices)\n",
    "    llm_response_cleaned = formatted_llm_response.drop(index=invalid_indices)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(user_response_cleaned, llm_response_cleaned)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = float(f1_score(user_response_cleaned, llm_response_cleaned, average=\"macro\"))\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = float(precision_score(user_response_cleaned, llm_response_cleaned, average=\"macro\"))\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = float(recall_score(user_response_cleaned, llm_response_cleaned, average=\"macro\"))\n",
    "\n",
    "    # Calculate Matthews correlation coefficient\n",
    "    mcc = float(matthews_corrcoef(user_response_cleaned, llm_response_cleaned))\n",
    "\n",
    "    # Calculate Cramer's V correlation\n",
    "    cramer_v = cramers_v(user_response_cleaned, llm_response_cleaned)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(user_response_cleaned, llm_response_cleaned)\n",
    "\n",
    "    # Calculate number of invalid entries\n",
    "    invalid_percent = len(invalid_indices) * 100 / len(formatted_llm_response)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"macro_f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"matthews_corrcoef\": mcc,\n",
    "        \"cramer_v_correlation\": cramer_v,\n",
    "        \"auc\":auc,\n",
    "        \"invalid_percent\": invalid_percent\n",
    "    }\n",
    "\n",
    "\n",
    "def clean_llm_response(response: str) -> str:\n",
    "    try:\n",
    "        response = response.lower()\n",
    "    except AttributeError:\n",
    "        return \"\"\n",
    "    \n",
    "    # Extract the first 10 characters and the last 10 characters of the response\n",
    "    first_10 = response[:10]\n",
    "    last_10 = response[-10:]\n",
    "\n",
    "    # Combine the first 10 and last 10 characters\n",
    "    combined = first_10 + \" \" + last_10\n",
    "\n",
    "    # Use regular expression to find 'yes', 'no', 'do not know', or 'prefer not to say'\n",
    "    match = re.search(r\"\\b(yes|no|do not know|prefer not to say)\\b\", combined)\n",
    "\n",
    "    # # Use regular expression to find 'Yes', 'yes', 'No', 'no', 'do not know', or 'prefer not to say'\n",
    "    # match = re.search(r\"\\b(yes|no|do not know|prefer not to say)\", response)\n",
    "    \n",
    "    # If a match is found, return the matched word\n",
    "    if match:\n",
    "        if match.group(0) in [\"yes\"]:\n",
    "            return \"Yes\"\n",
    "        elif match.group(0) in [\"no\"]:\n",
    "            return \"No\"\n",
    "        elif match.group(0) in [\"do not know\"]:\n",
    "            return \"Do not know\"\n",
    "        elif match.group(0) in [\"prefer not to say\"]:\n",
    "            return \"Prefer not to say\"\n",
    "        else:\n",
    "            raise ValueError(f\"{match.group(0)} is not considered\")\n",
    "\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Define the custom mapping function\n",
    "def map_response_string(response, question):\n",
    "    if pd.isnull(response):\n",
    "        return response\n",
    "    \n",
    "    if question == \"Do you think you will get a first shot of a COVID-19 vaccine within the first 6 weeks after the vaccine becomes available to you?\":\n",
    "        if response in [\"No\", \"Yes\", \"Do not know\", \"Prefer not to say\"]:\n",
    "            return response\n",
    "        else:\n",
    "            return \"Invalid\"\n",
    "    else:\n",
    "        raise ValueError(f\"{question} is not considered!\")\n",
    "    \n",
    "custom_labels = {\n",
    "    \"Start Date\":\"InterviewDate\",\n",
    "    \"What is your current age?\":\"Age\",\n",
    "    \"What is your gender?\":\"Gender\",\n",
    "    \"What is the highest educational qualification you have completed?\":\"Education\",\n",
    "    \"Which region do you live in?\":\"Region\",\n",
    "    \"Which distric do you live in?\":\"District\",\n",
    "    \"What is the name of the community you live in?\":\"Community\",\n",
    "    \"How many people live in your village?\":\"VillageSize\",\n",
    "    \"What is the distance in km of the nearest health clinic from where you live?\":\"NearestClinic\",\n",
    "    \"How many people live in the house together with you (NOT including you) at this moment?\":\"HouseholdSize\",\n",
    "    \"How many children below 18 years old are currently living in your home?\":\"NumChildren\",\n",
    "    \"What is your current working situation?\":\"Employment\",\n",
    "    \"How much (in Ghanaian Cedis) on average does your household spend in a typical week on food?\":\"FoodSpend\",\n",
    "    \"How much (in Ghanaian Cedis) on average does your household spend in a typical week on non-food items (electricity, water, rent, school fees)?\":\"NonFoodSpend\",\n",
    "    \"How would you rate the overall economic or financial condition of your household today?\":\"EconomicCondition\",\n",
    "    \"Do you have a registered mobile number?\":\"RegisteredMobile\",\n",
    "    \"How many family members do you have in another village?\":\"FamilyOtherVillage\",\n",
    "    \"How many friends and acquaintances who are not part of your family do you have in another village?\":\"FriendsOtherVillage\",\n",
    "    \"How many individuals can you identify in your social network? Think of friends and relatives that live close to you\":\"SocialNetwork\",\n",
    "    \"How often do you use social media?\":\"SocialMediaUse\",\n",
    "    \"Do you think you will get a first shot of a COVID-19 vaccine within the first 6 weeks after the vaccine becomes available to you?\": \"VaccineIntention\",\n",
    "}\n",
    "\n",
    "\n",
    "def plot_response_distribution(experiment_version: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots the distribution of responses for each feature in the given experiment version.\n",
    "\n",
    "    Parameters:\n",
    "        experiment_version (str): The version of the experiment.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    results = pd.read_excel(f'../results/{EXPERIMENT_ROUND}/{experiment_version}.xlsx', header=1)\n",
    "\n",
    "    # Drop rows with missing responses\n",
    "    results.dropna(subset=['user_response'], inplace=True)\n",
    "    results = results[~results[\"user_response\"].isin([\"Do not know\", \"Prefer not to say\"])].reset_index(drop=True)\n",
    "    \n",
    "    # Clean LLM response\n",
    "    results[\"llm_response\"] = results[\"llm_response\"].apply(clean_llm_response)\n",
    "\n",
    "    user_response = {}\n",
    "    llm_response = {}\n",
    "\n",
    "    for question in results['question'].unique():\n",
    "        user_resp = results[results['question'] == question]['user_response'].tolist()\n",
    "        llm_resp = results[results['question'] == question]['llm_response'].tolist()\n",
    "        \n",
    "        # Ensure each list has same number of items, filling with NaN if necessary\n",
    "        user_response[question] = user_resp + [np.nan] * (NUM_SUBJECTS - len(user_resp))\n",
    "        llm_response[question] = llm_resp + [np.nan] * (NUM_SUBJECTS - len(llm_resp))\n",
    "\n",
    "    user_response = pd.DataFrame(user_response)\n",
    "    llm_response = pd.DataFrame(llm_response)\n",
    "\n",
    "    # Convert columns to categorical\n",
    "    for col in user_response.columns:\n",
    "        user_response[col] = format_response(user_response[col].astype('category'))\n",
    "        user_response[col] = user_response[col].apply(lambda response: map_response_string(response, col))\n",
    "        llm_response[col] = format_response(llm_response[col].astype('category'))\n",
    "        llm_response[col] = llm_response[col].apply(lambda response: map_response_string(response, col))\n",
    "        \n",
    "    # Calculate Cramer's V for each pair of features\n",
    "    features = user_response.columns\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(nrows=len(features) // 2 + len(features) % 2, ncols=2, figsize=(20, 5 * (len(features) // 2 + len(features) % 2)))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes to easily use a single index\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "        user_counts = user_response[feature].value_counts().sort_index()\n",
    "        llm_counts = llm_response[feature].value_counts().sort_index()\n",
    "\n",
    "        # Ensure both user and llm responses have the same categories\n",
    "        all_categories = user_counts.index.union(llm_counts.index)\n",
    "        user_counts = user_counts.reindex(all_categories, fill_value=0)\n",
    "        llm_counts = llm_counts.reindex(all_categories, fill_value=0)\n",
    "\n",
    "        # Plotting\n",
    "        x = np.arange(len(all_categories))  # the label locations\n",
    "        width = 0.35  # the width of the bars\n",
    "\n",
    "        ax.bar(x - width/2, user_counts, width, alpha=0.5, label='User Response')\n",
    "        ax.bar(x + width/2, llm_counts, width, alpha=0.5, label='LLM Response')\n",
    "\n",
    "        ax.set_ylabel('Counts')\n",
    "        ax.set_title(custom_labels.get(feature, feature))\n",
    "        ax.set_xticks(x)\n",
    "\n",
    "        if custom_labels.get(feature, feature) == 'VaccineReason':\n",
    "            ax.set_xticklabels(all_categories, rotation=90)\n",
    "        else:\n",
    "            ax.set_xticklabels(all_categories)\n",
    "        \n",
    "        # Relabel y ticks\n",
    "        current_ytick_labels = ax.get_yticklabels()\n",
    "        custom_ytick_labels = [custom_labels.get(label.get_text(), label.get_text()) for label in current_ytick_labels]\n",
    "        ax.set_yticklabels(custom_ytick_labels)\n",
    "\n",
    "        ax.legend()\n",
    "    \n",
    "    # If there's an odd number of features, hide the last subplot if unused\n",
    "    if len(features) % 2 != 0:\n",
    "        axes[-1].set_visible(False)\n",
    "    plt.savefig(f'../results/{EXPERIMENT_ROUND}/response_distribution_{experiment_version}.png', dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold dataframes for each file's evaluation results\n",
    "all_evaluation_results = []\n",
    "\n",
    "# Loop through each .xlsx file in the results folder\n",
    "for file_path in glob.glob(f'../results/{EXPERIMENT_ROUND}/vaccine_financial_incentive_vaccinationintention_*.xlsx'):\n",
    "\n",
    "    if file_path.startswith(\"../results/round9/vaccine_financial_incentive_vaccinationintention_demographic\"):\n",
    "        continue\n",
    "\n",
    "    print(file_path)\n",
    "    # Extract experiment version from the file name\n",
    "    start = file_path.find('vaccine_financial_incentive_vaccinationintention_')\n",
    "    end = file_path.find('.xlsx')\n",
    "    experiment_version = file_path[start:end]\n",
    "\n",
    "    # Read the results from the file\n",
    "    results = pd.read_excel(file_path, header=1)\n",
    "    results = results[~results[\"user_response\"].isin([\"Do not know\", \"Prefer not to say\"])].reset_index(drop=True)\n",
    "    \n",
    "    # Clean LLM response\n",
    "    results[\"llm_response\"] = results[\"llm_response\"].apply(clean_llm_response)\n",
    "    \n",
    "    # Perform evaluation\n",
    "    evaluation_results = evaluate_responses(results)\n",
    "    evaluation_results['Experiment Version'] = experiment_version\n",
    "    \n",
    "    # Normalize the evaluation results and append to the list\n",
    "    evaluation_results = pd.json_normalize(evaluation_results, sep=' ')\n",
    "    evaluation_results = evaluation_results.rename(columns=lambda x: x.replace('evaluation_result', '\\n'))\n",
    "    all_evaluation_results.append(evaluation_results)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "all_evaluation_results = pd.concat(all_evaluation_results, ignore_index=True)\n",
    "\n",
    "# Save evaluation results to a CSV file\n",
    "all_evaluation_results.to_excel(f'../results/{EXPERIMENT_ROUND}/vaccinationintention_evaluation_results.xlsx', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "all_evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cohen_kappa(user_response: pd.Series, llm_response: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Cohen's kappa coefficient between user_response and llm_response.\n",
    "    \n",
    "    Args:\n",
    "        user_response (pd.Series): A pandas Series containing the user's responses.\n",
    "        llm_response (pd.Series): A pandas Series containing the LLM's responses.\n",
    "    \n",
    "    Returns:\n",
    "        float: Cohen's kappa coefficient.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    if len(user_response) != len(llm_response):\n",
    "        raise ValueError(\"Series must be of the same length\")\n",
    "    \n",
    "    return cohen_kappa_score(user_response, llm_response)\n",
    "\n",
    "\n",
    "def calculate_krippendorff_alpha(user_response: pd.Series, llm_response: pd.Series) -> float:\n",
    "    \"\"\"Calculate Krippendorff's alpha coefficient between user_response and llm_response.\n",
    "    \n",
    "    Args:\n",
    "        user_response (pd.Series): A pandas Series containing the user's responses.\n",
    "        llm_response (pd.Series): A pandas Series containing the LLM's responses.\n",
    "    \n",
    "    Returns:\n",
    "        float: Krippendorff's alpha coefficient.\n",
    "    \"\"\"\n",
    "    if len(user_response) != len(llm_response):\n",
    "        raise ValueError(\"Series must be of the same length\")\n",
    "    \n",
    "    # Prepare the data in the format required by Krippendorff's alpha function\n",
    "    data = [user_response.tolist(), llm_response.tolist()]\n",
    "\n",
    "    try:\n",
    "        return krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def calculate_proportion_agreement(user_response, llm_response) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the proportion agreement between two series containing responses.\n",
    "\n",
    "    Parameters:\n",
    "        user_response (pd.Series): A pandas Series containing the user's responses.\n",
    "        llm_response (pd.Series): A pandas Series containing the LLM's responses.\n",
    "\n",
    "    Returns:\n",
    "        float: The proportion agreement between the two series.\n",
    "    \"\"\"\n",
    "    agreement_count = (user_response == llm_response).sum()\n",
    "    total_count = len(user_response)\n",
    "    proportion_agreement = agreement_count / total_count\n",
    "    return proportion_agreement\n",
    "\n",
    "\n",
    "def calculate_tetrachoric_correlation(user_response, llm_response) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the tetrachoric correlation between two series containing responses.\n",
    "\n",
    "    Parameters:\n",
    "        user_response (pd.Series): A pandas Series containing the user's responses.\n",
    "        llm_response (pd.Series): A pandas Series containing the LLM's responses.\n",
    "\n",
    "    Returns:\n",
    "        float: The tetrachoric correlation between the two series.\n",
    "    \"\"\"\n",
    "    x = np.array(user_response)\n",
    "    y = np.array(llm_response)\n",
    "    \n",
    "    # Calculate the contingency table\n",
    "    n00 = np.sum((x == 0) & (y == 0))\n",
    "    n01 = np.sum((x == 0) & (y == 1))\n",
    "    n10 = np.sum((x == 1) & (y == 0))\n",
    "    n11 = np.sum((x == 1) & (y == 1))\n",
    "    \n",
    "    # Total number of observations\n",
    "    n = n00 + n01 + n10 + n11\n",
    "\n",
    "    # Proportions\n",
    "    p00 = n00 / n\n",
    "    p01 = n01 / n\n",
    "    p10 = n10 / n\n",
    "    p11 = n11 / n\n",
    "    \n",
    "    # Marginal proportions\n",
    "    p0_ = p00 + p01\n",
    "    p1_ = p10 + p11\n",
    "    p_0 = p00 + p10\n",
    "    p_1 = p01 + p11\n",
    "    \n",
    "    # Calculate the tetrachoric correlation\n",
    "    # Using the inverse of the cumulative distribution function (CDF) of the normal distribution\n",
    "    phi = (p00 * p11 - p01 * p10) / np.sqrt(p0_ * p1_ * p_0 * p_1 + 1e-10)\n",
    "    return phi\n",
    "\n",
    "def evaluate_responses_correlation(prompts_with_responses: pd.DataFrame, question) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate the LLM's ability to predict the ground truth responses.\n",
    "\n",
    "    Parameters:\n",
    "        prompts_with_responses (pd.DataFrame): A DataFrame containing the prompts and the corresponding responses.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics for each question.\n",
    "    \"\"\"\n",
    "\n",
    "    proportion_agreement = {\"question\":question, \"Metric\":\"Proportion Agreement\"}\n",
    "    tetrachoric_correlation = {\"question\":question, \"Metric\":\"Tetrachoric Correlation\"}\n",
    "    cohen_kappa = {\"question\":question, \"Metric\":\"Cohen's Kappa Coefficient\"}\n",
    "    krippendorff_alpha = {\"question\":question, \"Metric\":\"Krippendorff's Alpha Coefficient\"}\n",
    "\n",
    "    # Define the list of filters\n",
    "    filters = {\n",
    "        \"Whole Sample\": prompts_with_responses[\"What is your gender?\"].isin([\"Male\",\"Female\"]),\n",
    "        \"CDC Health\": prompts_with_responses[\"treatment\"] == \"CDC Health\",\n",
    "        \"Placebo\": prompts_with_responses[\"treatment\"] == \"Placebo\",\n",
    "        \"Low Cash\": prompts_with_responses[\"treatment\"] == \"Low Cash\",\n",
    "        \"High Cash\": prompts_with_responses[\"treatment\"] == \"High Cash\",\n",
    "        \"Male\": prompts_with_responses[\"What is your gender?\"] == \"Male\",\n",
    "        \"Female\": prompts_with_responses[\"What is your gender?\"] == \"Female\",\n",
    "        \"18-30 Years Old\": prompts_with_responses[\"What is your current age?\"] <= 30,\n",
    "        \"31-45 Years Old\": (prompts_with_responses[\"What is your current age?\"] > 30) & (prompts_with_responses[\"What is your current age?\"] <= 45),\n",
    "        \"46-60 Years Old\": (prompts_with_responses[\"What is your current age?\"] > 45) & (prompts_with_responses[\"What is your current age?\"] <= 60),\n",
    "        \"Over 60 Years Old\": prompts_with_responses[\"What is your current age?\"] > 60,\n",
    "        \"Central Region\": prompts_with_responses[\"Which region do you live in?\"] == \"Central\",\n",
    "        \"Eastern Region\": prompts_with_responses[\"Which region do you live in?\"] == \"Eastern\",\n",
    "    }\n",
    "\n",
    "    # Loop through each filter\n",
    "    for filter_name, filter in filters.items():\n",
    "        filtered_data = prompts_with_responses[filter]\n",
    "        filtered_data = filtered_data.dropna(subset=['user_response','llm_response']).reset_index(drop=True)\n",
    "\n",
    "        # Map the user and llm responses using the custom mapping function\n",
    "        user_mapped = filtered_data['user_response'].apply(lambda response: map_response(response, question))\n",
    "        llm_mapped = filtered_data['llm_response'].apply(lambda response: map_response(response, question))\n",
    "        proportion_agreement[filter_name] = calculate_proportion_agreement(user_mapped, llm_mapped)\n",
    "        tetrachoric_correlation[filter_name] = calculate_tetrachoric_correlation(user_mapped, llm_mapped)\n",
    "        cohen_kappa[filter_name] = calculate_cohen_kappa(user_mapped, llm_mapped)\n",
    "        krippendorff_alpha[filter_name] = calculate_krippendorff_alpha(user_mapped, llm_mapped)\n",
    "\n",
    "    return proportion_agreement, tetrachoric_correlation, cohen_kappa, krippendorff_alpha\n",
    "\n",
    "# Loop through each .xlsx file in the results folder\n",
    "for file_path in glob.glob(f'../results/{EXPERIMENT_ROUND}/vaccine_financial_incentive_vaccinationintention_*.xlsx'):\n",
    "    if file_path.startswith(\"../results/round9/vaccine_financial_incentive_vaccinationintention_demographic\"):\n",
    "            continue\n",
    "    \n",
    "    print(file_path)\n",
    "\n",
    "    # List to hold dataframes for each file's evaluation results\n",
    "    all_evaluation_results = []\n",
    "\n",
    "    # Extract experiment version from the file name\n",
    "    start = file_path.find('vaccine_financial_incentive_vaccinationintention_')\n",
    "    end = file_path.find('.xlsx')\n",
    "    experiment_version = file_path[start:end]\n",
    "    \n",
    "    # Read the results from the file\n",
    "    results = pd.read_excel(file_path, header=1)\n",
    "    results = results[~results[\"user_response\"].isin([\"Do not know\", \"Prefer not to say\"])].reset_index(drop=True)\n",
    "\n",
    "    # Clean LLM response\n",
    "    results[\"llm_response\"] = results[\"llm_response\"].apply(clean_llm_response)\n",
    "\n",
    "    for question in survey_questions:\n",
    "        question_results = results[results['question']==question].reset_index()\n",
    "    \n",
    "        # Perform evaluation\n",
    "        result_proportion_agreement, result_tetrachoric_correlation, result_cohen_kappa, result_krippendorff_alpha = evaluate_responses_correlation(question_results, question)\n",
    "        \n",
    "        # Normalize the evaluation results and append to the list\n",
    "        all_evaluation_results.append(result_proportion_agreement)\n",
    "        all_evaluation_results.append(result_tetrachoric_correlation)\n",
    "        all_evaluation_results.append(result_cohen_kappa)\n",
    "        all_evaluation_results.append(result_krippendorff_alpha)\n",
    "\n",
    "    # Convert results into a single dataframe\n",
    "    all_evaluation_results = pd.DataFrame(all_evaluation_results).T\n",
    "    all_evaluation_results.columns = all_evaluation_results.iloc[0]\n",
    "    all_evaluation_results = all_evaluation_results[1:]\n",
    "\n",
    "    # Save evaluation results to a CSV file\n",
    "    all_evaluation_results.to_excel(f'../results/{EXPERIMENT_ROUND}/evaluation_results_correlation_{experiment_version}.xlsx', index=True)\n",
    "\n",
    "all_evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the results\n",
    "# experiment_version = 'vaccine_financial_incentive_vaccinationintention_claude3.5sonnet_instruct'  # TODO need to be updated\n",
    "# plot_response_distribution(experiment_version=experiment_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic-agent-generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
